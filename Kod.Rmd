---
title: |
  <center> **Rekrutacja Code4LifeAcademy** </center>
  <center> **Zadanie 1** </center>
author: "<center> **Krzysztof Dyba** </center>"
date: "<center> `r Sys.Date()` </center>"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    theme: spacelab
    highlight: tango
---

<style>
body {
text-align: justify}
</style>

## **Wczytanie bibliotek**

```{r message = FALSE, warning = FALSE}
library("MASS")
library("e1071")
library("tidyr")
library("caret")
library("GGally")
library("ggplot2")
library("doParallel")
```


## **Wczytanie danych**

```{r}
dane = read.csv("C4L Academy - Data Science Graduate - IRISES dataset (2019-06).csv", sep = "|")
dane$Petal.Width[133] = "2.2"
dane$Petal.Width = as.numeric(as.character(dane$Petal.Width))
```

W 133 wierszu kolumny *Petal.Width* zamiast kropki jako separatora dziesiętnego użyto przecinka. Taki błąd powoduje nieprawidłowe oznaczenie typu danych jako tekstowy, a przy konwersji na postać liczbową zwraca w danej komórce brak danych (NA). Separator zmieniono na kropkę, a następnie typ kolumny na liczbowy.

## **Eksploracja danych** {.tabset .tabset-fade}

### Opis

```{r}
str(dane)
```

Zbiór danych składa się ze 150 obiektów i 5 zmiennych (czterech numerycznych i jednej kategoryzującej). Zmienne numeryczne kolejno określają długość i szerokość kielicha kwiatu (*sepal*) oraz długość i szerokość płatka kwiatu (*petal*). Wartości wyrażone są w centymetrach.

### Klasy

```{r collapse = TRUE}
levels(dane$Species)
table(dane$Species)
```

Zmienna kategoryzująca składa się z trzech gatunków irysów, tj. **setosa**, **versicolor** i **virginica**. Każdy rodzaj irysów zawiera taką samą liczbę obserwacji, a więc nie występuje problem niezbalansowania klas.

### Braki wartości

```{r collapse = TRUE}
apply(dane[1:4], 2, function(x) any(is.na(x)))
sum(is.na(dane$Sepal.Width))
which(is.na(dane$Sepal.Width))
dane$Sepal.Width[82] = round(mean(dane$Sepal.Width[dane$Species == "versicolor"], na.rm = TRUE), 1)
```

Tylko kolumna *Sepal.Width* posiadała jedną brakującą wartość (NA). Pomiar został pominięty dla irysa **versicolor**. Obliczono średnią wartość szerokości kielicha dla tego gatunku (tj. 2,78), a następnie uzupełniono brakujący pomiar.

### Wartości odstające

```{r fig.height = 3.5}
dane_long = gather(dane, "zmienna", "wartosc", 1:4)
ggplot(dane_long, aes(x = zmienna, y = wartosc)) + 
  geom_boxplot(aes(colour = Species)) +
  xlab("Zmienna") +
  ylab("Wartość [cm]") +
  labs(colour = "Gatunek") +
  theme_light()
```

W przypadku zmiennej *Sepal.Length* widoczna jest jedna wartość ujemna równa -4.8 cm. Jest to oczywiście wartość nieprawidłowa. Prawdopodobnie znak minus został dopisany omyłkowo. 

```{r}
dane$Sepal.Length[dane$Sepal.Length == -4.8] = abs(-4.8)
dane_long$wartosc[dane_long$wartosc == -4.8] = abs(-4.8)
```

Błąd poprawiono poprzez zmianę na wartość dodatnią.
Nie zauważono innych wartości silnie odstających, które wynikałyby z błędnego zapisu.

## **Analiza danych** 

```{r message = FALSE}
ggpairs(dane, mapping = aes(color = Species), 
        columns = c("Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width")) +
  theme_light()
```

### {.tabset .tabset-fade}

#### Statystyki

```{r}
aggregate(. ~ Species, data = dane, mean)
```

Powyżej zestawiono średnie wartości zmiennych objaśniających dla poszczególnych gatunków irysów. Gatunek **setosa** jest średnio najmniejszy pod względem długości i szerokości płatków kwiatu (*petal*), natomiast gatunek **virginica** charakteryzuje się ich największym średnim rozmiarem.

#### Korelacja
Gatunek **setosa** cechuję się największą korelacją równą 0,74 pomiędzy długością a szerokością kielicha kwiatu (*sepal*). Dla innych zmiennych korelacja jest mniejsza niż 0,33. <br>
Gatunek **versicolor** odznacza się największą korelacją między długością a szerokością płatka kwiatu (*petal*) wynoszącą 0,79. Mniejszą korelację równą 0,75 odnotowano dla długości płatka oraz szerokości kielich kwiatu. Pozostałe zmienne są umiarkowanie skorelowane. <br>
Gatunek **virginica** posiada największą zależność między długością płatka i długością kielicha kwiatu na poziomie 0,86. Najniższą korelację można zauważyć w przypadku szerokości płatka a długością kielicha kwiatu.

#### Rozkład
W większości przypadków rozkład zmiennych nie jest zbliżony do rozkładu normalnego. Wyjątek stanowią długość i szerokość płatków irysów gatunku **versicolor** i **virginica**.

#### Klasyfikacja

```{r fig.height = 3.5}
ggplot(dane_long, aes(wartosc, zmienna)) +
  geom_jitter(aes(colour = Species), width = 0, alpha = 0.8) +
  xlab("Wartość [cm]") +
  ylab("Zmienna") +
  labs(colour = "Gatunek") +
  theme_light()
```

Analizując dwie powyższe ryciny można bez problemu wydzielić gatunek **setosa** na podstawie dwóch zmiennych *Petal.Width* i *Petal.Length*. Większy problem może pojawić się przy klasyfikacji gatunków **versicolor** i **virginica**, ponieważ obiekty tych dwóch gatunków wzajemnie się pokrywają w niektórych przypadkach. Prawdopodobnie przy takiej sytuacji również zmienne *Petal.Width* i *Petal.Length* będą odgrywały najważniejszą rolę.

## **Uczenie maszynowe** {.tabset .tabset-fade}

### Podział zbioru

```{r}
# ustawienie ziarna losowości (powtarzalność wyników)
set.seed(1)

trainIndex = createDataPartition(dane$Species, p = 0.8, list = FALSE)
train = dane[ trainIndex, ]
test = dane[-trainIndex, ]
```

Zbiór danych wejściowych podzielono równomiernie z uwzględnieniem gatunków irysów na zbiór treningowy (120 obiektów) i testowy (30 obiektów).

### Trenowanie modeli

```{r} 
set.seed(1)
seeds = vector(mode = "list", length = 101) # length = number * repeats + 1
for(i in 1:101) seeds[[i]] = sample.int(n = 1000, 6)

# kroswalidacja 10-fold
fitControl = trainControl(method = "repeatedcv", 
                          number = 10, 
                          repeats = 10, 
                          seeds = seeds)

# równoległe tworzenie modeli
n_cores = detectCores() - 1
cl = makePSOCKcluster(n_cores)
registerDoParallel(cl)

# trenowanie modeli
SVM_mdl = train(Species ~ ., data = train, 
                method = "svmLinear2", 
                trControl = fitControl,
                metric = "Accuracy")

RF_mdl = train(Species ~ ., data = train,
               method = "ranger",
               trControl = fitControl,
               metric = "Accuracy")

LDA_mdl = train(Species ~ ., data = train,
                method = "lda2",
                trControl = fitControl,
                metric = "Accuracy")

stopCluster(cl)
```

Wybrano trzy najpopularniejsze algorytmy o potwierdzonej wysokiej skuteczności w literaturze naukowej, tj. metodę wektorów nośnych (**SVM**), lasy losowe (**RF**) i liniową analizę dyskryminacyjną (**LDA**). <br>

Do resamplingu użyto kroswalidację 10-fold, gdzie również zbiór treningowy dzielony jest na treningowy (9 foldów) i testowy (1 fold) dla wszystkich kombinacji i proces powtarzany jest n razy. Dzięki takiemu zabiegowi można uniknąć przeuczenia  (*overfitted*), tj. sytuacji, gdzie model nauczył się danych treningowych, a nie ogólnego trendu w danych. <br>

Za miarę skuteczności przyjęto dokładność (*accuracy*) definiowaną jako iloraz sumy klasyfikacji prawdziwie pozytywnych i prawdziwie negatywnych do wszystkich możliwości. Z racji iż zbiór danych testowych i treningowych jest zbalansowany, nie istnieją przesłanki o nieskuteczności (obciążeniu) tej miary. <br>

W celu skrócenia czasu obliczeń, zostawiono domyślne parametry optymalizacyjne w gridzie. Jednakże, aby uzyskać optymalne modele, przestrzeń optymalizacji parametrów powinna zostać rozszerzona, co tym samym wpłynie na czas potrzebny na uzyskanie wyników. <br>

Podział danych na zbiór treningowy i testowy oraz resampling są operacjami losowymi, a więc każde wywołanie zwróci inne wyniki. Aby zapewnić powtarzalność wyników i możliwość odtworzenia analizy ustawiono stałe ziarna losowości. <br>

Obliczenia zostały zrównoleglone za pomocą 3 wątków procesora.

### Porównanie modeli

```{r fig.height = 3.5}
resamps = resamples(list(SVM = SVM_mdl, RF = RF_mdl, LDA = LDA_mdl))
ggplot(resamps, metric = "Accuracy", conf.level = 0.99) +
  xlab("Model") +
  ylab("Dokładność") +
  labs(title = "Skuteczność klasyfikacji", subtitle = "Przedział ufności: 0,99") +
  theme_light()
```

Najbardziej skutecznym (o najwyższej wartości miary dokładności) okazał się model oparty o liniową analizę dyskryminacyjną (**LDA**) przy przedziale ufności równym 0,99. Końcowo wartość dokładności wyniosła ponad 0,98 w procesie resamplingu.

### Walidacja

```{r}
pred = predict(LDA_mdl, test)
confusionMatrix(pred, test$Species)
```

Następnie dokonano walidacji na podstawie wcześniej wyznaczonego zbioru testowego (niezależnego). Wyniki testu potwierdziły bardzo wysoką skuteczność modelu (*accuracy*) **LDA** wynoszącą w zaokrągleniu 0,97. Model pomylił się tylko raz na 30 przypadków (nastąpiło błędne przypisane gatunku **virginica** zamiast **versicolor**). Jednak już na etapie analizy danych przewidziano trudności w klasyfikacji tych dwóch gatunków, wynikające ze zbliżonych cech charakterystyki gatunkowej.

### Istotność zmiennych

```{r fig.height = 3.5}
imps = data.frame(varImp(LDA_mdl)$importance)
imps$zmienna = rownames(imps)
imps = gather(imps, "gatunek", "istotnosc", 1:3)

ggplot(imps, aes(x = reorder(zmienna, istotnosc), y = istotnosc)) +
  geom_col(width = 0.01, fill = "black") +
  geom_point() +
  coord_flip() +
  facet_wrap(. ~ gatunek) +
  xlab("Zmienna") +
  ylab("Istotność") +
  labs(subtitle = "Liniowa analiza dyskryminacyjna") +
  theme_light()
```

W przypadku modelu **LDA** potwierdziły się wcześniejsze przypuszczenia, że najbardziej pomocnymi w rozróżnieniu gatunków okażą się zmienne *Petal.Width* i *Petal.Length*. Najmniej istotną zmienną okazała się *Sepal.Width* dla gatunku **virginica**.

## **Podsumowanie**

Eksploracja danych ujawniła, że zbiór danych wejściowych zawierał pewne nieprawidłowości (np. wartość ujemna, brak wartości czy zły typ danych), które zostały poprawione. Równoliczność poszczególnych gatunków irysów zapewniła wiarygodną ocenę skuteczności klasyfikacji. <br>

Przeprowadzenie analizy danych pozwoliło odkryć korelację między pewnymi cechami badanych gatunków irysów, a także określić, które zmienne potencjalnie mogą okazać się najbardziej przydatne do opracowania modelu. <br>

Przetestowano trzy najpopularniejsze modele **SVM**, **RF** i **LDA**. Model **LDA** zapewnił najlepsze wyniki, tj. dla zbioru treningowego wynoszącą ponad **98%** poprawnych klasyfikacji, a dla danych testowych około **97%**. Uzyskane wyniki potwierdziły możliwości stosowania metod uczenia maszynowego do efektywnej i dokładnej klasyfikacji gatunków irysów. Opracowany i pozytywnie zweryfikowany model może zostać wykorzystany do celów komercyjnych. <br>

Wyniki niniejszego opracowania są w pełni powtarzalne, dzięki zastosowaniu jednakowego ziarna losowości.

## **Dalsze możliwości**

Mimo uzyskania klasyfikatora o bardzo dużej skuteczności, istnieją perspektywy poprawy wyników. Niemniej może okazać się, że klasyfikacja nie ulegnie poprawie, a jedynie zwiększy się czas obliczeń.

Proponowane dalsze działania:

+ redukcja wymiarowości poprzez analizę głównych składowych i transformacja danych (normalizacja i transformacja Boxa-Coxa), 
+ wykorzystanie algorytmu typu *gradient boosting* (**xgboost**),
+ zwiększenie przestrzeni parametrów optymalizacyjnych dla modeli **SVM** i **RF**.